"""
Project Service

Handles project file management, storage, and retrieval for generated code.
Manages the projects/ directory with UUID-based project organization.
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from uuid import UUID
from zipfile import ZipFile
from io import BytesIO

from ..config import get_config
from ..logging_config import get_logger
from ..models.generated_project import GeneratedProject, FileStructure

logger = get_logger()


class ProjectServiceError(Exception):
    """Base exception for project service errors."""
    pass


class ProjectService:
    """
    Service for managing generated code projects.

    Handles:
    - Project file storage and retrieval
    - File system organization
    - Project metadata management
    - File validation and cleanup
    """

    def __init__(self, projects_dir: Optional[str] = None):
        """
        Initialize project service.

        Args:
            projects_dir: Directory for storing projects (optional, uses config if not provided)
        """
        config = get_config()

        if projects_dir is None:
            projects_dir = config.system.projects_dir

        self.projects_dir = Path(projects_dir)
        self.projects_dir.mkdir(exist_ok=True)

        # Create subdirectories if needed
        (self.projects_dir / "temp").mkdir(exist_ok=True)
        (self.projects_dir / "archive").mkdir(exist_ok=True)

        logger.info(f"Project service initialized with directory: {self.projects_dir}")

    def _get_project_dir(self, project_id: UUID) -> Path:
        """Get the directory path for a specific project."""
        return self.projects_dir / str(project_id)

    def _get_project_metadata_file(self, project_id: UUID) -> Path:
        """Get the metadata file path for a project."""
        return self._get_project_dir(project_id) / "metadata.json"

    async def save_project(self, project_data: Dict, file_contents: Optional[Dict[str, str]] = None) -> GeneratedProject:
        """
        Save a generated project to the file system.

        Args:
            project_data: Project data dictionary
            file_contents: Optional dict mapping relative file paths to content

        Returns:
            GeneratedProject instance

        Raises:
            ProjectServiceError: If saving fails
        """
        try:
            # Convert to GeneratedProject model
            project = GeneratedProject(**project_data)
            project_id = UUID(project.id)

            # Create project directory
            project_dir = self._get_project_dir(project_id)
            project_dir.mkdir(exist_ok=True)

            # Save project files
            await self._save_project_files(project, project_dir, file_contents or {})

            # Save metadata
            metadata_file = self._get_project_metadata_file(project_id)
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(project.to_dict(), f, ensure_ascii=False, indent=2)

            logger.info(f"Project saved: {project.project_name} ({project_id})")
            return project

        except Exception as e:
            logger.error(f"Failed to save project: {e}")
            raise ProjectServiceError(f"保存项目失败: {e}")

    async def _save_project_files(self, project: GeneratedProject, project_dir: Path, file_contents: Dict[str, str]):
        """Save all project files to the directory."""
        def save_file_structure(node: FileStructure, current_path: Path):
            if node.type == "file":
                # Create the file with content (if available)
                file_path = current_path / node.name
                file_path.parent.mkdir(parents=True, exist_ok=True)

                # Get content for this file
                rel_path = str(file_path.relative_to(project_dir))
                content = file_contents.get(rel_path, "")

                # If no content provided, create a basic file
                if not content:
                    if node.name.endswith('.py'):
                        content = "# Generated by AI Code Flow\n"
                    elif node.name.endswith('.md'):
                        content = "# Generated Project\n\nThis project was generated by AI Code Flow.\n"
                    elif node.name.endswith('.txt') or 'requirements' in node.name:
                        content = "# Generated requirements\n"

                file_path.write_text(content, encoding='utf-8')

                logger.debug(f"Created file: {file_path}")

            elif node.type == "directory" and node.children:
                for child in node.children:
                    save_file_structure(child, current_path / node.name)

        # Start with the root directory
        save_file_structure(project.file_structure, project_dir)

    async def load_project_metadata(self, project_id: UUID) -> Optional[GeneratedProject]:
        """
        Load project metadata from disk.

        Args:
            project_id: Project identifier

        Returns:
            GeneratedProject instance or None if not found
        """
        try:
            metadata_file = self._get_project_metadata_file(project_id)
            logger.info(f"Loading project metadata for {project_id}, file: {metadata_file}")
            logger.info(f"Projects dir: {self.projects_dir}")
            logger.info(f"Metadata file exists: {metadata_file.exists()}")

            if not metadata_file.exists():
                logger.warning(f"Metadata file does not exist: {metadata_file}")
                return None

            with open(metadata_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            return GeneratedProject.from_dict(data)

        except Exception as e:
            logger.error(f"Failed to load project metadata {project_id}: {e}")
            return None

    async def get_project_files(self, project_id: UUID) -> Dict[str, str]:
        """
        Get all files for a project.

        Args:
            project_id: Project identifier

        Returns:
            Dictionary mapping file paths to contents
        """
        try:
            project_dir = self._get_project_dir(project_id)
            files = {}

            if not project_dir.exists():
                return files

            # Recursively collect all files
            for file_path in project_dir.rglob('*'):
                if file_path.is_file() and file_path.name != 'metadata.json':
                    # Get relative path from project directory
                    rel_path = file_path.relative_to(project_dir)

                    try:
                        content = file_path.read_text(encoding='utf-8')
                        files[str(rel_path)] = content
                    except Exception as e:
                        logger.warning(f"Failed to read file {file_path}: {e}")
                        files[str(rel_path)] = f"# Error reading file: {e}"

            return files

        except Exception as e:
            logger.error(f"Failed to get project files {project_id}: {e}")
            return {}

    async def create_project_zip(self, project_id: UUID) -> Optional[BytesIO]:
        """
        Create a ZIP archive containing all project files.

        Args:
            project_id: Project identifier

        Returns:
            BytesIO containing ZIP data, or None if failed
        """
        try:
            # Get all project files
            files = await self.get_project_files(project_id)

            if not files:
                logger.warning(f"No files found for project {project_id}")
                return None

            # Create ZIP in memory
            zip_buffer = BytesIO()

            with ZipFile(zip_buffer, 'w') as zip_file:
                for file_path, content in files.items():
                    # Write file content to ZIP
                    zip_file.writestr(file_path, content)

            zip_buffer.seek(0)
            return zip_buffer

        except Exception as e:
            logger.error(f"Failed to create ZIP for project {project_id}: {e}")
            return None

    def get_project_list(self) -> List[str]:
        """
        Get list of all project IDs.

        Returns:
            List of project ID strings
        """
        try:
            projects = []
            for item in self.projects_dir.iterdir():
                if item.is_dir() and item.name not in ['temp', 'archive']:
                    try:
                        # Validate it's a valid UUID directory
                        UUID(item.name)
                        projects.append(item.name)
                    except ValueError:
                        continue  # Skip non-UUID directories

            return projects

        except Exception as e:
            logger.error(f"Failed to get project list: {e}")
            return []

    async def delete_project(self, project_id: UUID) -> bool:
        """
        Delete a project and all its files.

        Args:
            project_id: Project identifier

        Returns:
            True if deleted successfully, False otherwise
        """
        try:
            project_dir = self._get_project_dir(project_id)

            if not project_dir.exists():
                return False

            # Move to archive instead of deleting immediately
            archive_dir = self.projects_dir / "archive" / str(project_id)
            archive_dir.parent.mkdir(exist_ok=True)

            if archive_dir.exists():
                import shutil
                shutil.rmtree(archive_dir)

            project_dir.rename(archive_dir)

            logger.info(f"Project archived: {project_id}")
            return True

        except Exception as e:
            logger.error(f"Failed to delete project {project_id}: {e}")
            return False

    async def cleanup_old_projects(self, max_age_days: int = 30) -> int:
        """
        Clean up old archived projects.

        Args:
            max_age_days: Maximum age in days for archived projects

        Returns:
            Number of projects cleaned up
        """
        try:
            archive_dir = self.projects_dir / "archive"
            if not archive_dir.exists():
                return 0

            import shutil
            from datetime import timedelta

            cutoff_date = datetime.now() - timedelta(days=max_age_days)
            cleaned_count = 0

            for item in archive_dir.iterdir():
                if item.is_dir() and item.stat().st_mtime < cutoff_date.timestamp():
                    shutil.rmtree(item)
                    cleaned_count += 1

            if cleaned_count > 0:
                logger.info(f"Cleaned up {cleaned_count} old archived projects")

            return cleaned_count

        except Exception as e:
            logger.error(f"Failed to cleanup old projects: {e}")
            return 0

    def get_storage_stats(self) -> Dict[str, int]:
        """
        Get storage statistics.

        Returns:
            Dictionary with storage statistics
        """
        try:
            total_size = 0
            project_count = 0

            for item in self.projects_dir.iterdir():
                if item.is_dir() and item.name not in ['temp', 'archive']:
                    try:
                        UUID(item.name)  # Validate it's a project directory
                        project_count += 1

                        # Calculate directory size
                        for file_path in item.rglob('*'):
                            if file_path.is_file():
                                total_size += file_path.stat().st_size
                    except (ValueError, OSError):
                        continue

            return {
                "total_projects": project_count,
                "total_size_bytes": total_size,
                "average_project_size": total_size // max(project_count, 1)
            }

        except Exception as e:
            logger.error(f"Failed to get storage stats: {e}")
            return {"total_projects": 0, "total_size_bytes": 0, "average_project_size": 0}
